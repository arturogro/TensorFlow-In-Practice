{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict if a given transaction is fraudulent or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "rng = np.random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the csv file name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filename = \"./dataset/creditcard.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set column keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeKey = \"Time\"\n",
    "v1Key = \"V1\"\n",
    "v2Key = \"V2\"\n",
    "v3Key = \"V3\"\n",
    "v4Key = \"V4\"\n",
    "v5Key = \"V5\"\n",
    "v6Key = \"V6\"\n",
    "v7Key = \"V7\"\n",
    "v8Key = \"V8\"\n",
    "v9Key = \"V9\"\n",
    "v10Key = \"V10\"\n",
    "v11Key = \"V11\"\n",
    "v12Key = \"V12\"\n",
    "v13Key = \"V13\"\n",
    "v14Key = \"V14\"\n",
    "v15Key = \"V15\"\n",
    "v16Key = \"V16\"\n",
    "v17Key = \"V17\"\n",
    "v18Key = \"V18\"\n",
    "v19Key = \"V19\"\n",
    "v20Key = \"V20\"\n",
    "v21Key = \"V21\"\n",
    "v22Key = \"V22\"\n",
    "v23Key = \"V23\"\n",
    "v24Key = \"V24\"\n",
    "v25Key = \"V25\"\n",
    "v26Key = \"V26\"\n",
    "v27Key = \"V27\"\n",
    "v28Key = \"V28\"\n",
    "amountKey = \"Amount\"\n",
    "classKey = \"Class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_columns = [timeKey, v1Key, v2Key, v3Key, v4Key, v5Key, v6Key, v7Key, v8Key, v9Key, v10Key, v11Key, v12Key, v13Key, v14Key, v15Key, v16Key, v17Key, v18Key, v19Key, v20Key, v21Key, v22Key, v23Key, v24Key, v25Key, v26Key, v27Key, v28Key, amountKey, classKey]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transaction labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_x_label = 'Time (in Seconds)'\n",
    "transactions_y_label = 'Number of Transactions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    df = pd.read_csv(train_filename, names= train_columns, delimiter=',', dtype={classKey: 'float32', timeKey: 'float32'}, skiprows=1)\n",
    "    return df\n",
    "\n",
    "train_data = get_train_data()\n",
    "\n",
    "def get_fraud_data():\n",
    "    df = train_data[train_data.Class == 1]\n",
    "    return df\n",
    "\n",
    "def get_normal_data():\n",
    "    df = train_data[train_data.Class == 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fraud_train_data = get_fraud_data()\n",
    "normal_train_data = get_normal_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fraudulent transactions figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = plt.figure()\n",
    "ax1 = f1.add_subplot(111)\n",
    "bins = 50\n",
    "ax1.hist(train_data.Time[train_data.Class == 1], bins = bins)\n",
    "ax1.set_title('Fraud')\n",
    "ax1.set_xlabel(time_x_label)\n",
    "ax1.set_ylabel(transactions_y_label)\n",
    "f1.savefig('f1.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal transactions figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f2 = plt.figure()\n",
    "ax2 = f2.add_subplot(111)\n",
    "ax2.hist(train_data.Time[train_data.Class == 0], bins = bins)\n",
    "ax2.set_title('Normal')\n",
    "ax2.set_xlabel(time_x_label)\n",
    "ax2.set_ylabel(transactions_y_label)\n",
    "f2.savefig('f2.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal/Fraud figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f3 = plt.figure()\n",
    "ax3 = f3.add_subplot(111)\n",
    "ax3.scatter(normal_train_data[timeKey].values, normal_train_data[amountKey].values, alpha=0.8, color='blue', label='normal')\n",
    "ax3.scatter(fraud_train_data[timeKey].values, fraud_train_data[amountKey].values, alpha=0.8, color='red', label='fraud')\n",
    "ax3.set_xlabel(time_x_label)\n",
    "ax3.set_ylabel(transactions_y_label)\n",
    "f3.savefig('f3.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new feature for normal (non-fraudulent) transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.loc[train_data.Class == 0, 'Normal'] = 1\n",
    "train_data.loc[train_data.Class == 1, 'Normal'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename 'Class' to 'Fraud'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.rename(columns={'Class': 'Fraud'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "training_dropout = 0.9\n",
    "accuracy_history = [] \n",
    "cost_history = []\n",
    "valid_accuracy_history = [] \n",
    "valid_cost_history = [] \n",
    "stop_early = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fraud = train_data[train_data.Fraud == 1]\n",
    "Normal = train_data[train_data.Normal == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set train_X equal to 80% of the fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = Fraud.sample(frac=0.8)\n",
    "train_X = pd.concat([train_X, Normal.sample(frac = 0.8)], axis = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set test_X equal to the transactions not in train_X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = train_data.loc[~train_data.index.isin(train_X.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = shuffle(train_X)\n",
    "test_X = shuffle(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Add target features to train_Y and test_Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_Y = train_X.Fraud\n",
    "train_Y = pd.concat([train_Y, train_X.Normal], axis=1)\n",
    "test_Y = test_X.Fraud\n",
    "test_Y = pd.concat([test_Y, test_X.Normal], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop fraud and normal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.drop(['Fraud','Normal'], axis = 1)\n",
    "test_X = test_X.drop(['Fraud','Normal'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of all of the features in train_X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = train_X.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform each feature in features so that it has a mean of 0 and standard deviation of 1; \n",
    "This helps with training the softmax algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    mean, std = train_data[feature].mean(), train_data[feature].std()\n",
    "    train_X.loc[:, feature] = (train_X[feature] - mean) / std\n",
    "    test_X.loc[:, feature] = (test_X[feature] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = train_X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_labels = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf Graph Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, num_features]) # fraud data parameters\n",
    "Y = tf.placeholder(tf.float32, [None, num_labels]) # normal and fraud => 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([num_features, num_labels]))\n",
    "b = tf.Variable(tf.zeros([num_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.softmax(tf.matmul(X, W) + b) # Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize error using cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_sum(Y * tf.log(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split testing data into validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = int(len(test_Y)/2)\n",
    "\n",
    "train_size = train_X.shape[0]\n",
    "n_samples = train_Y.shape[0]\n",
    "\n",
    "input_X = train_X.as_matrix()\n",
    "input_Y = train_Y.as_matrix()\n",
    "input_X_valid = test_X.as_matrix()[:split]\n",
    "input_Y_valid = test_Y.as_matrix()[:split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch:', 0, 'Accuracy =', '0.99925', 'Cost =', '1287.49500', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '169.53888')\n",
      "('Epoch:', 1, 'Accuracy =', '0.99929', 'Cost =', '1054.16113', 'Valid_Accuracy =', '0.99923', 'Valid_Cost = ', '145.38084')\n",
      "('Epoch:', 2, 'Accuracy =', '0.99930', 'Cost =', '985.10834', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '138.60538')\n",
      "('Epoch:', 3, 'Accuracy =', '0.99932', 'Cost =', '951.03955', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '135.90561')\n",
      "('Epoch:', 4, 'Accuracy =', '0.99931', 'Cost =', '940.63501', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '133.94820')\n",
      "('Epoch:', 5, 'Accuracy =', '0.99932', 'Cost =', '921.32153', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '133.27802')\n",
      "('Epoch:', 6, 'Accuracy =', '0.99930', 'Cost =', '921.00751', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '132.31937')\n",
      "('Epoch:', 7, 'Accuracy =', '0.99932', 'Cost =', '907.48688', 'Valid_Accuracy =', '0.99916', 'Valid_Cost = ', '132.43289')\n",
      "('Epoch:', 8, 'Accuracy =', '0.99931', 'Cost =', '903.96997', 'Valid_Accuracy =', '0.99916', 'Valid_Cost = ', '132.61819')\n",
      "('Epoch:', 9, 'Accuracy =', '0.99930', 'Cost =', '912.25470', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '131.13144')\n",
      "('Epoch:', 10, 'Accuracy =', '0.99932', 'Cost =', '898.01752', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '131.21292')\n",
      "('Epoch:', 11, 'Accuracy =', '0.99932', 'Cost =', '895.25110', 'Valid_Accuracy =', '0.99916', 'Valid_Cost = ', '131.37036')\n",
      "('Epoch:', 12, 'Accuracy =', '0.99931', 'Cost =', '905.93518', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '130.37221')\n",
      "('Epoch:', 13, 'Accuracy =', '0.99933', 'Cost =', '891.92651', 'Valid_Accuracy =', '0.99919', 'Valid_Cost = ', '130.48903')\n",
      "('Epoch:', 14, 'Accuracy =', '0.99933', 'Cost =', '891.05444', 'Valid_Accuracy =', '0.99916', 'Valid_Cost = ', '130.76401')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-8095425388c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Display logs after every 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mtrain_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mvalid_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_newCost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_X_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_Y_valid\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aj.gupa/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aj.gupa/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aj.gupa/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/aj.gupa/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aj.gupa/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    max_epoch = 0\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for batch in range(total_batch):\n",
    "            start_batch = batch * batch_size\n",
    "            end_batch = (1 + batch) * batch_size\n",
    "            batch_xs = input_X[start_batch : end_batch]\n",
    "            batch_ys = input_Y[start_batch : end_batch]\n",
    "            sess.run([optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "\n",
    "        # Display logs after every 10 epochs\n",
    "        if (epoch) % display_step == 0:\n",
    "            train_accuracy, newCost = sess.run([accuracy, cost], feed_dict={X: input_X, Y: input_Y})\n",
    "            valid_accuracy, valid_newCost = sess.run([accuracy, cost], feed_dict={X: input_X_valid, Y: input_Y_valid})\n",
    "\n",
    "            print (\"Epoch:\", epoch, \"Accuracy =\", \"{:.5f}\".format(train_accuracy), \"Cost =\", \"{:.5f}\".format(newCost), \"Valid_Accuracy =\", \"{:.5f}\".format(valid_accuracy), \"Valid_Cost = \", \"{:.5f}\".format(valid_newCost))\n",
    "            \n",
    "            # Record the results of the model\n",
    "            accuracy_history.append(train_accuracy)\n",
    "            cost_history.append(newCost)\n",
    "            valid_accuracy_history.append(valid_accuracy)\n",
    "            valid_cost_history.append(valid_newCost)\n",
    "\n",
    "            # If the model does not improve after 15 logs, stop the training.\n",
    "            if valid_accuracy < max(valid_accuracy_history) and epoch > 100:\n",
    "                stop_early += 1\n",
    "                if stop_early == 15:\n",
    "                    max_epoch = epoch\n",
    "                    break\n",
    "            else:\n",
    "                stop_early = 0\n",
    "\n",
    "    # Cost history figure\n",
    "    f4 = plt.figure()\n",
    "    ax4 = f4.add_subplot(111)\n",
    "    ax4.plot(range(len(cost_history)),cost_history,color='r')\n",
    "    ax4.axis([0,max_epoch,0,np.max(cost_history)])\n",
    "    f4.savefig('f4.png') \n",
    "                \n",
    "    print(\"Optimization Finished!\")\n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
